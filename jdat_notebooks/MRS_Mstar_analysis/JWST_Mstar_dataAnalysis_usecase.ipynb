{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "# MIRI MRS Spectroscopy of a Late M Star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** Extract spatial-spectral features from IFU cube and measure their attributes.<br>\n",
    "**Data:** MIRISIM simulation of AGB star.<br>\n",
    "**Tools:** specutils, spectral_cube, photutils, astropy, aplpy, scipy.<br>\n",
    "**Cross-intrument:** MIRI<br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n",
    "**Note**: This notebook includes MIRI simulated data cubes obtained using MIRISim (https://wiki.miricle.org//bin/view/Public/MIRISim_Public)\n",
    "and run through the JWST pipeline (https://jwst-pipeline.readthedocs.io/en/latest/) of\n",
    "point sources with spectra representative of late M type stars.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook analyzes one star represented by a dusty SED corresponding to the ISO SWS spectrum of\n",
    "W Per from Kraemer et al. (2002) and Sloan et al. (2003) to cover the MRS spectral range 5-28 microns.  Analysis of JWST spectral cubes requires extracting spatial-spectral features of interest and measuring their attributes. \n",
    "\n",
    "The first part of the notebook will process the datacube and automatically detect and extract spectra (summed over its spatial region) for all point sources in the cube.  Then it will read in a datacube generated at Stage 3 of the JWST pipeline as a representative example of an IR data cube.  The analysis will use `photutils` to automatically detect sources in the continuum image and use an aperture mask generated with `spectral-cube` to extract the spectra of each point source in the data cube.\n",
    "\n",
    "The second part of the notebook will perform data analysis using `specutils`.  Specifically, it will fit a model photosphere/blackbody to the spectra.  Then it will calculate the centroids, line integrated flux and equivalent width for each dust and molecular feature. \n",
    "\n",
    "## To Do:\n",
    "- Make function to extract spectra from datacube using an apeture.\n",
    "- Replace blackbody fit to the photosphere part of the spectra with a stellar photosphere model.\n",
    "- Make sure errors have been propagated correctly in the caculation of centroids, line integrated flux and\n",
    "equivalent widths.\n",
    "- Make simple function within the `specutils` framework to fit a continium and measure centroids, line integrated flux and\n",
    "equivalent widths of broad solid state and molecular features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import useful python packages\n",
    "import numpy as np\n",
    "\n",
    "# Import packages to display images inline in the notebook\n",
    "import matplotlib.pyplot as plt    \n",
    "%matplotlib inline   \n",
    "\n",
    "# Set general plotting options\n",
    "params={'legend.fontsize':'18','axes.labelsize':'18',\n",
    "        'axes.titlesize':'18','xtick.labelsize':'18',\n",
    "        'ytick.labelsize':'18','lines.linewidth':2,'axes.linewidth':2,'animation.html': 'html5'}\n",
    "plt.rcParams.update(params)\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import astropy packages \n",
    "from astropy import units as u\n",
    "from astropy.io import ascii\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table, vstack\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "from astropy.io import fits # added by BAS on 8 April 2021\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "\n",
    "# To find stars in the MRS spectralcubes and do aperture photometry\n",
    "from photutils import DAOStarFinder, CircularAperture\n",
    "\n",
    "# To deal with 1D spectrum\n",
    "from specutils import Spectrum1D\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.manipulation import box_smooth, extract_region, SplineInterpolatedResampler\n",
    "from specutils.analysis import line_flux, centroid, equivalent_width\n",
    "from specutils.spectra import SpectralRegion\n",
    "from specutils import SpectrumList\n",
    "\n",
    "# To make nice plots with WCS axis\n",
    "import aplpy\n",
    "\n",
    "# To fit a curve to the data\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths to the Data and Outputs\n",
    "\n",
    "Use MIRISim JWST pipeline processed data in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pipeline\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "from jwst.extract_1d import Extract1dStep\n",
    "import json\n",
    "import glob\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "import crds\n",
    "from jdaviz.app import Application\n",
    "import asdf\n",
    "from photutils import aperture_photometry\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do calwebb_detector1 pipeline\n",
    "\n",
    "allshortfiles=glob.glob('/filepath/and/files/using/asterisks*/selecting/mirisim_MIRIFUSHORT_simulations_*_files.fits')\n",
    "alllongfiles=glob.glob('/filepath/and/files/using/asterisks*/selecting/mirisim_MIRIFULONG_simulations_*_files.fits')\n",
    "\n",
    "pipe1short = Detector1Pipeline()\n",
    "\n",
    "# run calwebb_detector1 on the MIRIFUSHORT data separate from MIRIFULONG data, as it saves time this way\n",
    "for shortfile in allshortfiles:\n",
    "    print(shortfile)\n",
    "    baseshort,remaindershort = shortfile.split('.')\n",
    "    \n",
    "    # in the following line, use the YYYYMMDD from the folders with your mirisim simulations\n",
    "    beforestuffshort,dateafterstuffshort = shortfile.split('YYYYMMDD_')\n",
    "    datestringshort,afterstuffshort = dateafterstuffshort.split('_mirisim')\n",
    "    \n",
    "    pipe1short.refpix.skip = True\n",
    "    pipe1short.output_file = baseshort+datestringshort\n",
    "    \n",
    "    pipe1short.run(shortfile)\n",
    "\n",
    "pipe1long = Detector1Pipeline()\n",
    "\n",
    "for longfile in alllongfiles:\n",
    "    print(longfile)\n",
    "    baselong,remainderlong = longfile.split('.')\n",
    "    \n",
    "    # in the following line, use the YYYYMMDD from the folders with your mirisim simulations\n",
    "    beforestufflong,dateafterstufflong = longfile.split('YYYYMMDD_')\n",
    "    datestringlong,afterstufflong = dateafterstufflong.split('_mirisim')\n",
    "    \n",
    "    pipe1long.refpix.skip = True\n",
    "    pipe1long.output_file = baselong+datestringlong\n",
    "    \n",
    "    pipe1long.run(longfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do calwebb_spec2 pipeline\n",
    "\n",
    "allshortfiles2 = glob.glob('det_image_*_MIRIFUSHORT_*_rate.fits')\n",
    "alllongfiles2 = glob.glob('det_image_*_MIRIFULONG_*_rate.fits')\n",
    "\n",
    "for short2file in allshortfiles2:\n",
    "    print(short2file)\n",
    "    pipe2short = Spec2Pipeline()\n",
    "    base2short,remainder2short = short2file.split('.')\n",
    "    \n",
    "    pipe2short.straylight.skip = True\n",
    "    # in the following line, replace HHMMSS with the HHMMSS part of one of the folders for your mirisim simulations\n",
    "    if (short2file == 'det_image_seq1_MIRIFUSHORT_12LONGexp1HHMMSS_rate.fits'):\n",
    "        print('this one will have the level 2b cube built')\n",
    "    else:\n",
    "        pipe2short.cube_build.skip = True\n",
    "    pipe2short.extract_1d.skip = True\n",
    "    pipe2short.output_file = base2short\n",
    "        \n",
    "    pipe2short.run(short2file)\n",
    "\n",
    "for long2file in alllongfiles2:\n",
    "    print(long2file)\n",
    "    pipe2long = Spec2Pipeline()\n",
    "    base2long,remainder2long = long2file.split('.')\n",
    "    \n",
    "    pipe2long.straylight.skip = True\n",
    "    # in the following line, replace hhmmss with the hhmmss part of one of the folders for your mirisim simulations\n",
    "    if (long2file == 'det_image_seq1_MIRIFULONG_34SHORTexp1hhmmss_rate.fits'):\n",
    "        print('this one will have the level 2b cube built')\n",
    "    else:\n",
    "        pipe2long.cube_build.skip = True\n",
    "    pipe2long.extract_1d.skip = True\n",
    "    pipe2long.output_file = base2long\n",
    "    \n",
    "    pipe2long.run(long2file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the following line, replace hhmmss with the hhmmss part of the same folder you used in the previous cell \n",
    "#    for your MIRIFULONG simulation\n",
    "l_cube_file='det_image_seq1_MIRIFULONG_34SHORTexp1hhmmss_s3d.fits'\n",
    "# in the following line, replace HHMMSS with the HHMMSS part of the same folder you used in the previous cell\n",
    "#    for your MIRIFUSHORT simulation\n",
    "s_cube_file='det_image_seq1_MIRIFUSHORT_12LONGexp1HHMMSS_s3d.fits'\n",
    "\n",
    "with fits.open(s_cube_file) as hdu_s_cube:\n",
    "    s_cube=hdu_s_cube['SCI'].data\n",
    "    s_med_cube=np.zeros((s_cube.shape[1],s_cube.shape[2]))\n",
    "    for a in range(s_cube.shape[1]):\n",
    "        for b in range(s_cube.shape[2]):\n",
    "            s_med_cube[a,b]=np.median(s_cube[:,a,b])\n",
    "\n",
    "mean, median, std = sigma_clipped_stats(s_med_cube, sigma = 2.0)\n",
    "\n",
    "# Get a list of sources using a dedicated source detection algorithm\n",
    "# Find sources at least 3* background (typically)\n",
    "\n",
    "daofind = DAOStarFinder(fwhm = 2.0, threshold = 3. * std)\n",
    "sources = daofind(s_med_cube - median) \n",
    "print(\"\\n Number of sources in field: \", len(sources))\n",
    "\n",
    "# Positions in pixels\n",
    "positions = Table([sources['xcentroid'], sources['ycentroid']])\n",
    "\n",
    "# Convert to RA & Dec (ICRS)\n",
    "peakpixval=np.zeros(len(sources['xcentroid']))\n",
    "for count_s, _ in enumerate(sources):\n",
    "    peakpixval[count_s]=s_med_cube[int(np.round(sources['xcentroid'][count_s])),int(np.round(sources['ycentroid'][count_s]))]\n",
    "print('peak pixel x =')\n",
    "print(sources['xcentroid'][np.argmax(peakpixval)])\n",
    "print('peak pixel y =')\n",
    "print(sources['ycentroid'][np.argmax(peakpixval)])\n",
    "\n",
    "plt.imshow(s_med_cube,vmin=0,vmax=100)#.value)\n",
    "plt.tight_layout()\n",
    "plt.scatter(sources['xcentroid'], sources['ycentroid'],c=\"red\",marker=\"+\",s=50)\n",
    "plt.scatter(sources['xcentroid'][np.argmax(peakpixval)],sources['ycentroid'][np.argmax(peakpixval)],c='black',marker='+',s=50)\n",
    "plt.show()\n",
    "\n",
    "f0=fits.open(s_cube_file)\n",
    "w0=WCS(f0[('sci',1)].header,f0)\n",
    "f0.close()\n",
    "\n",
    "radec=w0.all_pix2world([sources['xcentroid'][np.argmax(peakpixval)]],[sources['ycentroid'][np.argmax(peakpixval)]],[1],1)\n",
    "# last argument should be 1 to make the reference pixel work out correctly\n",
    "ra_ptsrc=radec[0][0]\n",
    "dec_ptsrc=radec[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('det_image_*_cal.fits')\n",
    "targra=ra_ptsrc\n",
    "targdec=dec_ptsrc\n",
    "for thisfile in all_files:\n",
    "    base,remainder = thisfile.split('.')\n",
    "    outfilename=base+'_fix.'+remainder\n",
    "    print(outfilename)\n",
    "    \n",
    "    with fits.open(thisfile) as hduthis:\n",
    "        hduthis['SCI'].header['SRCTYPE']='POINT'\n",
    "        hduthis[0].header['TARG_RA']=targra\n",
    "        hduthis[0].header['TARG_DEC']=targdec\n",
    "        hduthis.writeto(outfilename,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up needed reference file(s) for spec3\n",
    "\n",
    "file_all_list = glob.glob('det_image_*_cal_fix.fits')\n",
    "\n",
    "asnall = asn_from_list.asn_from_list(file_all_list, rule=DMS_Level3_Base,product_name='combine_dithers_all_exposures')\n",
    "\n",
    "asnallfile='for_spec3_all.json'\n",
    "with open(asnallfile, 'w') as fpall:\n",
    "    fpall.write(asnall.dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do calwebb_spec3 pipeline\n",
    "\n",
    "pipe3ss = Spec3Pipeline()\n",
    "pipe3ss.master_background.skip = True\n",
    "pipe3ss.mrs_imatch.skip = True\n",
    "pipe3ss.outlier_detection.skip = True\n",
    "pipe3ss.resample_spec.skip = True\n",
    "pipe3ss.combine_1d.skip = True\n",
    "pipe3ss.use_source_posn='True'\n",
    "pipe3ss.subtract_background='True'\n",
    "pipe3ss.output_file = 'allspec3'\n",
    "pipe3ss.run(asnallfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlall=[]\n",
    "fnuall=[]\n",
    "dfnuall=[]\n",
    "bandall=[]\n",
    "\n",
    "speclist=[]\n",
    "\n",
    "ch1short_extractfile='combine_dithers_all_exposures_ch1-short_x1d.fits'\n",
    "with fits.open(ch1short_extractfile) as hduch1short:\n",
    "    wlch1short=hduch1short['EXTRACT1D'].data['wavelength']\n",
    "    fnuch1short=hduch1short['EXTRACT1D'].data['flux']\n",
    "    dfnuch1short=hduch1short['EXTRACT1D'].data['error']\n",
    "ch1shortspec=Spectrum1D(spectral_axis=wlch1short*u.micron,flux=fnuch1short*u.Jy,uncertainty=dfnuch1short,meta={'band':'ch1short'})\n",
    "speclist.append(ch1shortspec)\n",
    "for ind1s in range(len(wlch1short)):\n",
    "    wlall.append(wlch1short[ind1s])\n",
    "    fnuall.append(fnuch1short[ind1s])\n",
    "    dfnuall.append(dfnuch1short[ind1s])\n",
    "    bandall.append('ch1short')\n",
    "\n",
    "ch1medium_extractfile='combine_dithers_all_exposures_ch1-medium_x1d.fits'\n",
    "with fits.open(ch1medium_extractfile) as hduch1medium:\n",
    "    wlch1medium=hduch1medium['EXTRACT1D'].data['wavelength']\n",
    "    fnuch1medium=hduch1medium['EXTRACT1D'].data['flux']\n",
    "    dfnuch1medium=hduch1medium['EXTRACT1D'].data['error']\n",
    "ch1mediumspec=Spectrum1D(spectral_axis=wlch1medium*u.micron,flux=fnuch1medium*u.Jy,uncertainty=dfnuch1medium,meta={'band':'ch1medium'})\n",
    "speclist.append(ch1mediumspec)\n",
    "for ind1m in range(len(wlch1medium)):\n",
    "    wlall.append(wlch1medium[ind1m])\n",
    "    fnuall.append(fnuch1medium[ind1m])\n",
    "    dfnuall.append(dfnuch1medium[ind1m])\n",
    "    bandall.append('ch1medium')\n",
    "\n",
    "ch1long_extractfile='combine_dithers_all_exposures_ch1-long_x1d.fits'\n",
    "with fits.open(ch1long_extractfile) as hduch1long:\n",
    "    wlch1long=hduch1long['EXTRACT1D'].data['wavelength']\n",
    "    fnuch1long=hduch1long['EXTRACT1D'].data['flux']\n",
    "    dfnuch1long=hduch1long['EXTRACT1D'].data['error']\n",
    "ch1longspec=Spectrum1D(spectral_axis=wlch1long*u.micron,flux=fnuch1long*u.Jy,uncertainty=dfnuch1long,meta={'band':'ch1long'})\n",
    "speclist.append(ch1longspec)\n",
    "for ind1l in range(len(wlch1long)):\n",
    "    wlall.append(wlch1long[ind1l])\n",
    "    fnuall.append(fnuch1long[ind1l])\n",
    "    dfnuall.append(dfnuch1long[ind1l])\n",
    "    bandall.append('ch1long')\n",
    "\n",
    "ch2short_extractfile='combine_dithers_all_exposures_ch2-short_x1d.fits'\n",
    "with fits.open(ch2short_extractfile) as hduch2short:\n",
    "    wlch2short=hduch2short['EXTRACT1D'].data['wavelength']\n",
    "    fnuch2short=hduch2short['EXTRACT1D'].data['flux']\n",
    "    dfnuch2short=hduch2short['EXTRACT1D'].data['error']\n",
    "ch2shortspec=Spectrum1D(spectral_axis=wlch2short*u.micron,flux=fnuch2short*u.Jy,uncertainty=dfnuch2short,meta={'band':'ch2short'})\n",
    "speclist.append(ch2shortspec)\n",
    "for ind2s in range(len(wlch2short)):\n",
    "    wlall.append(wlch2short[ind2s])\n",
    "    fnuall.append(fnuch2short[ind2s])\n",
    "    dfnuall.append(dfnuch2short[ind2s])\n",
    "    bandall.append('ch2short')\n",
    "\n",
    "ch2medium_extractfile='combine_dithers_all_exposures_ch2-medium_x1d.fits'\n",
    "with fits.open(ch2medium_extractfile) as hduch2medium:\n",
    "    wlch2medium=hduch2medium['EXTRACT1D'].data['wavelength']\n",
    "    fnuch2medium=hduch2medium['EXTRACT1D'].data['flux']\n",
    "    dfnuch2medium=hduch2medium['EXTRACT1D'].data['error']\n",
    "ch2mediumspec=Spectrum1D(spectral_axis=wlch2medium*u.micron,flux=fnuch2medium*u.Jy,uncertainty=dfnuch2medium,meta={'band':'ch2medium'})\n",
    "speclist.append(ch2mediumspec)\n",
    "for ind2m in range(len(wlch2medium)):\n",
    "    wlall.append(wlch2medium[ind2m])\n",
    "    fnuall.append(fnuch2medium[ind2m])\n",
    "    dfnuall.append(dfnuch2medium[ind2m])\n",
    "    bandall.append('ch2medium')\n",
    "\n",
    "ch2long_extractfile='combine_dithers_all_exposures_ch2-long_x1d.fits'\n",
    "with fits.open(ch2long_extractfile) as hduch2long:\n",
    "    wlch2long=hduch2long['EXTRACT1D'].data['wavelength']\n",
    "    fnuch2long=hduch2long['EXTRACT1D'].data['flux']\n",
    "    dfnuch2long=hduch2long['EXTRACT1D'].data['error']\n",
    "ch2longspec=Spectrum1D(spectral_axis=wlch2long*u.micron,flux=fnuch2long*u.Jy,uncertainty=dfnuch2long,meta={'band':'ch2long'})\n",
    "speclist.append(ch2longspec)\n",
    "for ind2l in range(len(wlch2long)):\n",
    "    wlall.append(wlch2long[ind2l])\n",
    "    fnuall.append(fnuch2long[ind2l])\n",
    "    dfnuall.append(dfnuch2long[ind2l])\n",
    "    bandall.append('ch2long')\n",
    "\n",
    "ch3short_extractfile='combine_dithers_all_exposures_ch3-short_x1d.fits'\n",
    "with fits.open(ch3short_extractfile) as hduch3short:\n",
    "    wlch3short=hduch3short['EXTRACT1D'].data['wavelength']\n",
    "    fnuch3short=hduch3short['EXTRACT1D'].data['flux']\n",
    "    dfnuch3short=hduch3short['EXTRACT1D'].data['error']\n",
    "ch3shortspec=Spectrum1D(spectral_axis=wlch3short*u.micron,flux=fnuch3short*u.Jy,uncertainty=dfnuch3short,meta={'band':'ch3short'})\n",
    "speclist.append(ch3shortspec)\n",
    "for ind3s in range(len(wlch3short)):\n",
    "    wlall.append(wlch3short[ind3s])\n",
    "    fnuall.append(fnuch3short[ind3s])\n",
    "    dfnuall.append(dfnuch3short[ind3s])\n",
    "    bandall.append('ch3short')\n",
    "\n",
    "ch3medium_extractfile='combine_dithers_all_exposures_ch3-medium_x1d.fits'\n",
    "with fits.open(ch3medium_extractfile) as hduch3medium:\n",
    "    wlch3medium=hduch3medium['EXTRACT1D'].data['wavelength']\n",
    "    fnuch3medium=hduch3medium['EXTRACT1D'].data['flux']\n",
    "    dfnuch3medium=hduch3medium['EXTRACT1D'].data['error']\n",
    "ch3mediumspec=Spectrum1D(spectral_axis=wlch3medium*u.micron,flux=fnuch3medium*u.Jy,uncertainty=dfnuch3medium,meta={'band':'ch3medium'})\n",
    "speclist.append(ch3mediumspec)\n",
    "for ind3m in range(len(wlch3medium)):\n",
    "    wlall.append(wlch3medium[ind3m])\n",
    "    fnuall.append(fnuch3medium[ind3m])\n",
    "    dfnuall.append(dfnuch3medium[ind3m])\n",
    "    bandall.append('ch3medium')\n",
    "\n",
    "ch3long_extractfile='combine_dithers_all_exposures_ch3-long_x1d.fits'\n",
    "with fits.open(ch3long_extractfile) as hduch3long:\n",
    "    wlch3long=hduch3long['EXTRACT1D'].data['wavelength']\n",
    "    fnuch3long=hduch3long['EXTRACT1D'].data['flux']\n",
    "    dfnuch3long=hduch3long['EXTRACT1D'].data['error']\n",
    "ch3longspec=Spectrum1D(spectral_axis=wlch3long*u.micron,flux=fnuch3long*u.Jy,uncertainty=dfnuch3long,meta={'band':'ch3long'})\n",
    "speclist.append(ch3longspec)\n",
    "for ind3l in range(len(wlch3long)):\n",
    "    wlall.append(wlch3long[ind3l])\n",
    "    fnuall.append(fnuch3long[ind3l])\n",
    "    dfnuall.append(dfnuch3long[ind3l])\n",
    "    bandall.append('ch3long')\n",
    "\n",
    "ch4short_extractfile='combine_dithers_all_exposures_ch4-short_x1d.fits'\n",
    "with fits.open(ch4short_extractfile) as hduch4short:\n",
    "    wlch4short=hduch4short['EXTRACT1D'].data['wavelength']\n",
    "    fnuch4short=hduch4short['EXTRACT1D'].data['flux']\n",
    "    dfnuch4short=hduch4short['EXTRACT1D'].data['error']\n",
    "ch4shortspec=Spectrum1D(spectral_axis=wlch4short*u.micron,flux=fnuch4short*u.Jy,uncertainty=dfnuch4short,meta={'band':'ch4short'})\n",
    "speclist.append(ch4shortspec)\n",
    "for ind4s in range(len(wlch4short)):\n",
    "    wlall.append(wlch4short[ind4s])\n",
    "    fnuall.append(fnuch4short[ind4s])\n",
    "    dfnuall.append(dfnuch4short[ind4s])\n",
    "    bandall.append('ch4short')\n",
    "\n",
    "ch4medium_extractfile='combine_dithers_all_exposures_ch4-medium_x1d.fits'\n",
    "with fits.open(ch4medium_extractfile) as hduch4medium:\n",
    "    wlch4medium=hduch4medium['EXTRACT1D'].data['wavelength']\n",
    "    fnuch4medium=hduch4medium['EXTRACT1D'].data['flux']\n",
    "    dfnuch4medium=hduch4medium['EXTRACT1D'].data['error']\n",
    "ch4mediumspec=Spectrum1D(spectral_axis=wlch4medium*u.micron,flux=fnuch4medium*u.Jy,uncertainty=dfnuch4medium,meta={'band':'ch4medium'})\n",
    "speclist.append(ch4mediumspec)\n",
    "for ind4m in range(len(wlch4medium)):\n",
    "    wlall.append(wlch4medium[ind4m])\n",
    "    fnuall.append(fnuch4medium[ind4m])\n",
    "    dfnuall.append(dfnuch4medium[ind4m])\n",
    "    bandall.append('ch4medium')\n",
    "\n",
    "ch4long_extractfile='combine_dithers_all_exposures_ch4-long_x1d.fits'\n",
    "with fits.open(ch4long_extractfile) as hduch4long:\n",
    "    wlch4long=hduch4long['EXTRACT1D'].data['wavelength']\n",
    "    fnuch4long=hduch4long['EXTRACT1D'].data['flux']\n",
    "    dfnuch4long=hduch4long['EXTRACT1D'].data['error']\n",
    "ch4longspec=Spectrum1D(spectral_axis=wlch4long*u.micron,flux=fnuch4long*u.Jy,uncertainty=dfnuch4long,meta={'band':'ch4long'})\n",
    "speclist.append(ch4longspec)\n",
    "for ind4l in range(len(wlch4long)):\n",
    "    wlall.append(wlch4long[ind4l])\n",
    "    fnuall.append(fnuch4long[ind4l])\n",
    "    dfnuall.append(dfnuch4long[ind4l])\n",
    "    bandall.append('ch4long')\n",
    "\n",
    "wlallnp=np.array(wlall)\n",
    "fnuallnp=np.array(fnuall)\n",
    "dfnuallnp=np.array(dfnuall)\n",
    "\n",
    "mdict=dict()\n",
    "mdict={'band'+str(indall):bandall[indall] for indall in range(len(bandall))}\n",
    "dictlist=mdict.items()\n",
    "allspec=Spectrum1D(spectral_axis=wlallnp*u.micron,flux=fnuallnp*u.Jy,uncertainty=dfnuallnp,meta=mdict)\n",
    "\n",
    "origspecfile='63702662.txt'\n",
    "origdata=ascii.read(origspecfile)\n",
    "wlorig=origdata['col1']\n",
    "fnujyorig=origdata['col2']*0.001# comes in as mJy, change to Jy to compare with pipeline output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(wlorig,fnujyorig,'.',color='grey',markersize=1)\n",
    "plt.plot(wlch1short,fnuch1short,'.',color='purple',markersize=1)\n",
    "plt.plot(wlch1medium,fnuch1medium,'.',color='blue',markersize=1)\n",
    "plt.plot(wlch1long,fnuch1long,'.',color='green',markersize=1)\n",
    "plt.plot(wlch2short,fnuch2short,'.',color='yellow',markersize=1)\n",
    "plt.plot(wlch2medium,fnuch2medium,'.',color='orange',markersize=1)\n",
    "plt.plot(wlch2long,fnuch2long,'.',color='red',markersize=1)\n",
    "plt.plot(wlch3short,fnuch3short,'.',color='purple',markersize=1)\n",
    "plt.plot(wlch3medium,fnuch3medium,'.',color='blue',markersize=1)\n",
    "plt.plot(wlch3long,fnuch3long,'.',color='green',markersize=1)\n",
    "plt.plot(wlch4short,fnuch4short,'.',color='yellow',markersize=1)\n",
    "plt.plot(wlch4medium,fnuch4medium,'.',color='orange',markersize=1)\n",
    "plt.plot(wlch4long,fnuch4long,'.',color='red',markersize=1)\n",
    "plt.xlabel('wavelength (microns)')\n",
    "plt.ylabel('flux (Jy)')\n",
    "plt.xlim(4.8,28.0)\n",
    "plt.ylim(0.0,0.15)\n",
    "plt.title('Spectrum from Extract1d in Spec3')\n",
    "plt.tight_layout()\n",
    "plt.savefig('agb_spectrum.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speclist[2].meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app = Application(configuration='cubeviz')# when doing Cubeviz, first run this block.\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1short_cubefile='combine_dithers_all_exposures_ch1-long_s3d.fits'\n",
    "app.load_data(ch1short_cubefile)# When this block is run, the spectrum will appear in the Cubeviz viewer above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_viewer('spectrum-viewer').show()# This just shows the spectrum part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_input = app.get_data_from_viewer('spectrum-viewer')\n",
    "# This is the spectrum - wavelength and flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_agb = app.get_data_from_viewer('spectrum-viewer', 'Subset 1')\n",
    "spec_agb\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(spec_agb.spectral_axis,spec_agb.flux)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load and Display the Data cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to detect the point source in the datacube and extract and plot the spectra for each source\n",
    "\n",
    "**Developer note** Finding a way to streamline the process of detecting sources within a data cube and extracting their\n",
    "spectra would be extremely valuable.\n",
    "\n",
    "For data cubes like the JWST/MIRI MRS information on the point sources in the FOV and also obtaining a source subtracted\n",
    " data cube will be necessary (See the `PampelMuse` software for an example on how spectral extraction is implemented for\n",
    "  near-IR data cubes like MUSE).\n",
    "\n",
    "Note these backgrounds of diffuse emission can be quite complex.\n",
    "\n",
    "On these source extracted data cubes (see `SUBTRES` in `PampelMuse`) I would like to produce moment maps\n",
    "(https://casa.nrao.edu/Release3.4.0/docs/UserMan/UserManse41.html) and Position-Velocity (PV) diagrams\n",
    "(https://casa.nrao.edu/Release4.1.0/doc/UserMan/UserManse42.html).\n",
    "\n",
    "### 1) Use `Photutils` to detect stars/point sources in the continuum image\n",
    "\n",
    "The first step of the analysis is to identify those sources for which it is feasible to extract spectra from the IFU\n",
    "data. Ideally we can estimate the signal-to-noise ratio (S/N) for all sources in the cube, do a number of checks to\n",
    "determine the status of every source and loop through these (brightest first) to extract the spectra.\n",
    "\n",
    "### 2) Extract the spectra from the datacube using `SpectralCube`\n",
    "\n",
    "**Note** There are multiple ways of extracting spectra from datacubes. The simplest is slice the cube along a single\n",
    "pixel but this is not ideal for point sources which should cover multiple pixels.\n",
    "Here I use *Aperture Extraction*. \n",
    "\n",
    "- The flux from each point source was obtained via a circular aperture. This requires you to mask the data, and make a\n",
    "circular mask and a maskedsubcube.\n",
    "\n",
    "- A background measured using a square/rectangular aperture sliced in pixel coordinates to produce a sub-cube.\n",
    "\n",
    "- A annulus surrounding the point source to measure the local background. \n",
    "\n",
    "- Using predefined regions from DS9 etc. to create a mask [`Not used here`].\n",
    "\n",
    "*If have a small number of data cubes selecting the source extraction region and background region manually using\n",
    "`cubeviz` would be useful here.*\n",
    "\n",
    "Mathematical operation e.g. `max, mean, sum, median, std` should then be applied to the region in the aperture.\n",
    "\n",
    "Below I show a few different options from the simple to the complex, which takes into account the background emission\n",
    "within the data cube. Taking into account the background may not always be the preferred method but the option should\n",
    "always be available when using an aperture extraction.\n",
    "\n",
    "#### Steps to find the background\n",
    "\n",
    "1) Define a background region either as an annulus or as a rectangle away from the source\n",
    "\n",
    "2) Find the median of all the background pixels to account for variations \n",
    "\n",
    "3) Find number of pixels in background and number of pixels in the point source aperture\n",
    "\n",
    "4) Find the sum of all the pixels in the point source aperture\n",
    "\n",
    "5) Correct for background using the sum star flux minus median of background * pixels in star aperture\n",
    "\n",
    "\n",
    "\n",
    "**Advanced Developer Note** Using Aperture Extraction to obtain the spectra for each source in the data cube is still\n",
    "very simplistic. It should be noted that the MIRI aperture changes as a function of wavelength, the steps above do not\n",
    "account for this.\n",
    "A good example of software that looks at extracting point sources from datacubes is: `PampelMuse`, by Sebastian Kamann. \n",
    "https://gitlab.gwdg.de/skamann/pampelmuse; https://ui.adsabs.harvard.edu/abs/2013A%26A...549A..71K/abstract\n",
    "\n",
    "An `optimal spectrum extraction` procedure would take into account the varying PSF through the cube, to produce an\n",
    "accurate spectra with the maximum possible signal-to-noise ratio. This weights the extracted data by the S/N of each\n",
    "pixel (Horne 1986) and would be ideal for when there is a complex background or for extracting spatially-blended source.\n",
    "For small cubes its best to fit a PSF profile to all resolved sources simultaneously, but this might not be possible in\n",
    "larger data sets.\n",
    "\n",
    "**Advanced Developer Note 2** In dense fields like globular clusters, with a significant number of unresolved sources or\n",
    " in embedded star-forming clusters, a more advanced treatment of the background would be necessary. For instance using a\n",
    " homogeneous grid across the field of view with parameters controlling the bin size would be ideal. If a variable\n",
    " background is not accounted for in a PSF extraction systematic residuals in the data would be present where background\n",
    " is over or underestimated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect, extract and plot 1D spectrum of each source in the cube \n",
    "\n",
    "### First automatically identify all the point sources in the cube using `photutils`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If point sources are present in the cube extract and plot the spectrum of each source\n",
    "\n",
    "#### In the cell below we:\n",
    "\n",
    "1) Extract a spectra for each detected object using aperture photometry, and a circular masked region.\n",
    "\n",
    "2) Make an estimate of the background in the datacube using both: an annulus around each source and a box region away\n",
    "from the source - this box and annulus is hard coded and not ideal for other datasets or multiple cubes.\n",
    "\n",
    "3) Generate a background corrected spectrum.\n",
    "\n",
    "4) Plots the spectra and its various background corrected versions. \n",
    "\n",
    "5) Convert the spectra into Jy.\n",
    "\n",
    "6) Write each of the spectra to a file. (They could be put into a `specutils` `Spectrum1D` object at this stage but I\n",
    "have not done this here.) This file is loaded by all other routines to do analysis on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data analysis - on the extracted spectra using `specutils`\n",
    "With the present lack of JWST flight data, we instead use the SWS spectra of an dusty AGB star, a cool M-star.\n",
    "\n",
    "Developer Note: (BAS 1 Sep 2021) Add filter to SpectrumList.read(); for example, filter='*.fits' would only find FITS files in the directory.\n",
    "\n",
    "Developer Note: (BAS 5 Sep 2021) Fix the uncertainties here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd='.'\n",
    "splist=SpectrumList.read(ddd)#### (BAS 1 Sep 2021)\n",
    "\n",
    "###### FUTURE MIRI SPLICER FUNCTION HERE #######\n",
    "\n",
    "wlallorig=[]\n",
    "fnuallorig=[]\n",
    "dfnuallorig=[]\n",
    "for bndind in range(len(splist)):\n",
    "    for wlind in range(len(splist[bndind].spectral_axis)):\n",
    "        wlallorig.append(splist[bndind].spectral_axis[wlind].value)\n",
    "        fnuallorig.append(splist[bndind].flux[wlind].value)\n",
    "        dfnuallorig.append(splist[bndind].uncertainty[wlind].array)\n",
    "\n",
    "wlallarr=np.array(wlallorig)\n",
    "fnuallarr=np.array(fnuallorig)\n",
    "dfnuallarr=np.array(dfnuallorig)\n",
    "srtind=np.argsort(wlallarr)\n",
    "wlall=wlallarr[srtind]\n",
    "fnuall=fnuallarr[srtind]\n",
    "dfnuall=(0.0001)*np.ones(len(fnuall))#### (BAS 5 Sep 2021) I put 0.0001, but it could be anything. Fix uncertainties here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = wlall*u.micron# Wavelength: microns\n",
    "fl = fnuall*u.Jy# Fnu:  Jy\n",
    "efl = dfnuall*u.Jy# Error flux: Jy\n",
    "\n",
    "# Make a 1D spectrum object\n",
    "spec = Spectrum1D(spectral_axis = wav, flux = fl, uncertainty = StdDevUncertainty(efl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Reading in a spectra comprised of multiple spectral components this file may have a spectral order column. In\n",
    "many instances these orders are not correctly stitched together due to issues with background and flux calibration. A\n",
    "spectral file with an order column that can read into the `Spectrum1D` is necessary to do corrections and scaling on\n",
    "each segment individually to fix the jumps between the spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec=splist\n",
    "# Apply a 5 pixel boxcar smoothing to the spectrum\n",
    "spec_bsmooth = box_smooth(spec, width = 5)   \n",
    "\n",
    "# Plot the spectrum & smoothed spectrum to inspect features \n",
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(spec.spectral_axis, spec.flux, label = 'Source')\n",
    "plt.plot(spec.spectral_axis, spec_bsmooth.flux, label = 'Smoothed')\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.ylim(-0.05,0.15)\n",
    "\n",
    "plt.legend(frameon = False, fontsize = 'medium')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a continuum - find the best-fitting template (stellar photosphere model or blackbody)\n",
    "\n",
    "**Note** - Would idealy like to fit the photosphere with a set of Phoenix Models - but cant get that to work.\n",
    "I think `template_comparison` may be a good function here to work with the Phoenix Models which have been setup to\n",
    "interface with `pysynphot`.\n",
    "\n",
    "For now switching to a blackbody.\n",
    "\n",
    "- For AGB stars with a photosphere component fit a stellar photosphere model or a blackbody to short wavelength end of\n",
    "the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackbody_Fnu(lam, T, A):\n",
    "    \"\"\" Blackbody as a function of wavelength (um) and temperature (K).\n",
    "        Function returns the Planck function in f_nu units\n",
    "        # [Y Jy] = 1.0E+23 * [X erg/cm^2/s/Hz] = 10E+26  [X Watts/m^2/Hz]\n",
    "    \"\"\"\n",
    "    from scipy.constants import h, k, c\n",
    "    lam = 1e-6 * lam                                              # convert to metres\n",
    "    bb_nu = 2*h*c / (lam**3 * (np.exp(h*c / (lam*k*T)) - 1))      # units of W/m^2/Hz/Steradian ; f_nu units\n",
    "    return A * bb_nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only want to fit to a small wavelength range at the start of the spectra\n",
    "phot_fit_region = [5.0,8.0]# Microns\n",
    "\n",
    "# Trim the specrum to the region showing a stellar photosphere\n",
    "sub_region_phot = SpectralRegion([(phot_fit_region[0], phot_fit_region[1])] * u.micron)\n",
    "sub_spectrum_phot = extract_region(spec, sub_region_phot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit BB to the data\n",
    "def phot_fn(wa, T1, A):\n",
    "    return blackbody_Fnu(wa, T1, A) \n",
    "\n",
    "popt, pcov = curve_fit(phot_fn, sub_spectrum_phot.spectral_axis.value,\n",
    "                       sub_spectrum_phot.flux.value, p0=(3000, 10000),\n",
    "                       sigma=sub_spectrum_phot.uncertainty.quantity)\n",
    "\n",
    "# Get the best fitting parameter value and their 1 sigma errors\n",
    "best_t1, best_a1 = popt\n",
    "sigma_t1, sigma_a1 = np.sqrt(np.diag(pcov))\n",
    "\n",
    "ybest = blackbody_Fnu(spec.spectral_axis.value, best_t1, best_a1)\n",
    "\n",
    "print ('Parameters of best-fitting model:')\n",
    "print ('T1 = %.2f +/- %.2f' % (best_t1, sigma_t1))\n",
    "\n",
    "degrees_of_freedom = len(sub_spectrum_phot.spectral_axis.value) - 2\n",
    "\n",
    "resid = (sub_spectrum_phot.flux.value - phot_fn(sub_spectrum_phot.spectral_axis.value, *popt)) \\\n",
    "        / sub_spectrum_phot.uncertainty.quantity\n",
    "\n",
    "chisq = np.dot(resid, resid)\n",
    "\n",
    "print ('nchi2 %.2f' % (chisq.value / degrees_of_freedom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectrum & the model fit to the short wavelength region of the data.\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(spec.spectral_axis, spec.flux, label = 'Source')\n",
    "plt.plot(spec.spectral_axis, ybest, label = 'BB')\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.title(\"Spectrum with blackbody fit\")\n",
    "plt.legend(frameon = False, fontsize = 'medium')\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.05,0.15)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Now subtract the BB and plot the underlying dust continuum\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(spec.spectral_axis, spec.flux.value - ybest,color='purple', label = 'Dust spectra')\n",
    "plt.axhline(0, color='r', linestyle = 'dashdot', alpha=0.5)\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.title(\"Continuum-subtracted spectrum\")\n",
    "plt.legend(frameon = False, fontsize = 'medium')\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.05,0.15)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now have the dust continuum want to look for features and measure their properties.\n",
    "\n",
    "Want to find:\n",
    "- Equivalent width\n",
    "- Equivalent flux\n",
    "- Optical depth\n",
    "- Centroids = wavelength with half the flux on either side\n",
    "\n",
    "#### As an example lets focus on the amorphous silicate 10 micron region.\n",
    "\n",
    "**Method - used repeatedly**\n",
    "\n",
    "- Fit a spline to the photosphere continuum subtracted spectra excluding the feature in this fit.\n",
    "- Trim the spectra to that wavelength region as the spline is now a different size to the full wavelength range of the\n",
    "spectra.\n",
    "- Make a continuum subtracted and and continuum normalised spectra.\n",
    "- Convert the units of the flux from Jy to W/m^2/wavelength for nice units post line integration. \n",
    "- Determine the feature line flux in units of W/m^2 and the feature centroid. Use continuum subtracted spectra.\n",
    "- Determine the feature equivalent width. Use continuum normalised spectra.\n",
    "- Make sure errors have been propagated correctly.\n",
    "- Store these results in a table \n",
    "- Several molecular and dust features are normally present in the spectra. Repeat for each feature.\n",
    "\n",
    "**Note**\n",
    "This seems like a long winded way to do this. Is there a simpler approach?\n",
    "\n",
    "> For instance a tool that takes four wavelengths, fits a line using the data from  lam0 to lam1 and lam2 to lam3, then\n",
    ">passes the continuum-subtracted  spectrum for line integration from lam1 to lam2 with error propagation is needed\n",
    ">several times for dust features. But with the current spectra1d framework this takes many steps to write manually and\n",
    ">is beyond tedious after doing this for 2 features let alone 20+.  Similar framework is also needed for the integrated\n",
    ">line centroid with uncertainty, and the extracted equivalent width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a spline to the 10 micron feature to isolate it.\n",
    "\n",
    "bbsub_spectra = spec - ybest     # continuum subtracted spectra - Dust only\n",
    "\n",
    "# Fit a local continuum between the flux densities at: 8.0 - 8.1 & 14.9 - 15.0 microns\n",
    "# (i.e. excluding the line itself)\n",
    "\n",
    "sw_region = 8.0   #lam0\n",
    "sw_line = 8.1     #lam1\n",
    "lw_line = 14.9    #lam2\n",
    "lw_region = 15.0  #lam3\n",
    "\n",
    "# Zoom in on the line complex & extract\n",
    "line_reg_10 = SpectralRegion([(sw_region*u.um, lw_region*u.um)])\n",
    "line_spec = extract_region(bbsub_spectra, line_reg_10)\n",
    "\n",
    "# Fit a local continuum - exclude the actual dust feature when doing the fit\n",
    "\n",
    "lgl_fit = fit_generic_continuum(line_spec, \n",
    "                                exclude_regions = SpectralRegion([(sw_line*u.um, \n",
    "                                                                   lw_line*u.um)])) \n",
    "\n",
    "# Determine Y values of the line continuum\n",
    "line_y_continuum = lgl_fit(line_spec.spectral_axis) \n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Generate a continuum subtracted and continuum normalised spectra\n",
    "\n",
    "line_spec_norm   = Spectrum1D(spectral_axis = line_spec.spectral_axis, flux = line_spec.flux/line_y_continuum, uncertainty = StdDevUncertainty(np.zeros(len(line_spec.spectral_axis))))\n",
    "line_spec_consub = Spectrum1D(spectral_axis = line_spec.spectral_axis, flux = line_spec.flux - line_y_continuum, uncertainty = StdDevUncertainty(np.zeros(len(line_spec.spectral_axis))))\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Plot the dust feature & continuum fit to the region\n",
    "\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(line_spec.spectral_axis, line_spec.flux.value,\n",
    "         label = 'Dust spectra 10 micron region')\n",
    "\n",
    "plt.plot(line_spec.spectral_axis, line_y_continuum, label = 'Local continuum')\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.title(\"10$\\mu$m feature plus local continuum\")\n",
    "plt.legend(frameon = False, fontsize = 'medium')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Plot the continuum subtracted 10 micron feature\n",
    "\n",
    "plt.figure(figsize = (8,4))\n",
    "\n",
    "plt.plot(line_spec.spectral_axis, line_spec_consub.flux, color='green',\n",
    "         label = 'continuum subtracted')\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.title(\"Continuum subtracted 10$\\mu$m feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Line flux; Line Centroid; Equivalent width\n",
    "# NOTE: Where are errors computed with these functions?\n",
    "\n",
    "line_centroid = centroid(line_spec_consub, SpectralRegion(sw_line*u.um, lw_line*u.um))\n",
    "\n",
    "\n",
    "line_flux_val = line_flux(line_spec_consub, SpectralRegion(sw_line*u.um, lw_line*u.um))\n",
    "\n",
    "equivalent_width_val = equivalent_width(line_spec_norm)\n",
    "\n",
    "# Hack to convert the line flux value into more conventional units\n",
    "# Necessary as spectra has mixed units: f_nu+lambda\n",
    "line_flux_val = (line_flux_val * u.micron).to(u.W * u.m**-2 * u.micron,\n",
    "                                              u.spectral_density(line_centroid)) / u.micron\n",
    "\n",
    "print(\"Line_centroid: {:.6} \".format(line_centroid))\n",
    "print(\"Integrated line_flux: {:.6} \".format(line_flux_val))\n",
    "print(\"Equivalent width: {:.6} \".format(equivalent_width_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developer note** The hack in the cell above is necessary, as the line flux computed by `specutils` would return\n",
    "units of Jy micron and it is hard to convert this into conventional units within the current `specutils` framework.\n",
    "Line flux units should be in units of in W/m^2. Implementing a simple way to convert the flux and associate error to\n",
    "other units when dealing with a 1d spectal object with \"mixed\" spectral x and y axis units seems necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the optical depth of the 10 micron feature\n",
    "\n",
    "tau = -(np.log(line_spec.flux.value / line_y_continuum.value))\n",
    "\n",
    "optdepth_spec = Spectrum1D(spectral_axis = line_spec.spectral_axis,\n",
    "                           flux = tau*(u.Jy/u.Jy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developer note** Trying to put optical depth into a Spectrum1D object results in an error as no units.\n",
    "But the optical depth is unit-less - using (u.Jy/u.Jy) as work arround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optical depth of the 10 micron region vs wavelength\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(optdepth_spec.spectral_axis, optdepth_spec.flux)\n",
    "plt.xlabel(\"Wavelength ({:latex})\".format(spec.spectral_axis.unit))\n",
    "plt.ylabel('Tau') \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** At this point repeat *all* the steps above to isolate solid-state features e.g. for the forsterite feature at\n",
    "at approx 13.3 microns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now try looking for low crystalline silicate features  at 23, 28, 33 microns in the spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbsub_spectra = spec - ybest  # photosphere continuum subtracted spectra\n",
    "\n",
    "spline_points = [20.0,21.3,22.0,24.4,25.5]*u.micron\n",
    "sp_pt_bin_full_width = 0.5\n",
    "\n",
    "# Developer's Note: (BAS 3 Sep 2021).  I am currently computing the bin fluxes by taking a median to avoid \n",
    "#   the influence of emission lines and/or noise.  Would be better to do something like a sigma-clipped mean?\n",
    "spline_fluxes_orig = []\n",
    "for splind in range(len(spline_points)):\n",
    "    binind=(((bbsub_spectra.spectral_axis/u.micron) > \n",
    "             ((spline_points[splind]/u.micron)-(0.5*sp_pt_bin_full_width))) & \n",
    "            ((bbsub_spectra.spectral_axis/u.micron) < \n",
    "             ((spline_points[splind]/u.micron)+(0.5*sp_pt_bin_full_width)))).nonzero()\n",
    "    spline_fluxes_orig.append(np.median(bbsub_spectra.flux[binind[0]]/u.Jy))\n",
    "spline_fluxes_nparray=np.array(spline_fluxes_orig)\n",
    "spline_fluxes=spline_fluxes_nparray*u.Jy\n",
    "\n",
    "fluxes_for_spline = Spectrum1D(spectral_axis = spline_points, flux = spline_fluxes)\n",
    "\n",
    "fluxc_resample = SplineInterpolatedResampler()\n",
    "\n",
    "line_reg_other = SpectralRegion([(spline_points[0],spline_points[-1])])\n",
    "extract_region_other = extract_region(bbsub_spectra,line_reg_other)\n",
    "\n",
    "print(extract_region_other.spectral_axis)\n",
    "\n",
    "# Generate a spline fit to the dust continuum\n",
    "spline_spec = fluxc_resample(fluxes_for_spline,extract_region_other.spectral_axis)\n",
    "bbsub_spec_local=fluxc_resample(bbsub_spectra,extract_region_other.spectral_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the underlying dust continuum and spline fit\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(bbsub_spectra.spectral_axis, bbsub_spectra.flux, label = 'Dust spectra')\n",
    "plt.plot(bbsub_spec_local.spectral_axis,bbsub_spec_local.flux,'o',color='orange',label='Local Dust spectrum')\n",
    "plt.plot(spline_spec.spectral_axis,spline_spec.flux,'.',color='green',label='Spline points')\n",
    "\n",
    "\n",
    "plt.axhline(0, color='r', linestyle='dashdot', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.title(\"Continuum-subtracted spectrum with spline\")\n",
    "plt.legend(frameon = False, fontsize = 'medium')\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.1,0.2)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot the underlying dust continuum and spline fit\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(bbsub_spectra.spectral_axis, bbsub_spectra.flux.value, label = 'Dust spectra')\n",
    "plt.plot(bbsub_spec_local.spectral_axis,bbsub_spec_local.flux,'o',color='orange',label='Local Dust spectrum')\n",
    "plt.plot(spline_spec.spectral_axis,spline_spec.flux,'.',color='green',label='Spline points')\n",
    "\n",
    "plt.xlim(spline_points[0].value, spline_points[-1].value)\n",
    "plt.ylim(-0.1,0.2)\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel(\"Flux ({:latex})\".format(spec.flux.unit))\n",
    "plt.title(\"Zoom of continuum-subtracted spectrum with spline\")\n",
    "plt.legend(frameon = False, fontsize = 'medium')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbsub_spec_consub = Spectrum1D(spectral_axis = bbsub_spec_local.spectral_axis, \n",
    "                               flux = bbsub_spec_local.flux - spline_spec.flux, \n",
    "                               uncertainty = StdDevUncertainty(np.zeros(len(bbsub_spec_local.spectral_axis))))\n",
    "bbsub_spec_norm   = Spectrum1D(spectral_axis = bbsub_spec_local.spectral_axis, \n",
    "                               flux = bbsub_spec_local.flux/spline_spec.flux, \n",
    "                               uncertainty = StdDevUncertainty(np.zeros(len(bbsub_spec_local.spectral_axis))))\n",
    "\n",
    "plt.plot(bbsub_spec_consub.spectral_axis,bbsub_spec_consub.flux)\n",
    "\n",
    "# Calculate the Line flux; Line Centroid; Equivalent width\n",
    "# NOTE: Where are errors computed with these functions?\n",
    "bbsub_centroid_local = centroid(bbsub_spec_consub, SpectralRegion(spline_points[0],spline_points[-1]))\n",
    "\n",
    "bbsub_flux_val = line_flux(bbsub_spec_consub, SpectralRegion(spline_points[0],spline_points[-1]))\n",
    "\n",
    "equivalent_width_local_val = equivalent_width(bbsub_spec_norm)\n",
    "\n",
    "# Hack to convert the line flux value into more conventional units\n",
    "# Necessary as spectra has mixed units: f_nu+lambda\n",
    "bbsub_flux_val = (bbsub_flux_val * u.micron).to(u.W * u.m**-2 * u.micron,\n",
    "                                              u.spectral_density(bbsub_centroid_local)) / u.micron\n",
    "\n",
    "print(\"Line_centroid: {:.6} \".format(bbsub_centroid_local))\n",
    "print(\"Integrated line_flux: {:.6} \".format(bbsub_flux_val))\n",
    "print(\"Equivalent width: {:.6} \".format(equivalent_width_local_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developer note** By fitting a spline to a sub region the spectral shapes are no longer the same.\n",
    "` bbsub_spectra.flux.value - spline_spec.flux.value` now brakes. Would need to trim the spectrum to the spline size to\n",
    "start looking closely for low contrast dust features and again measure their properties (see above). Some  wrapper to\n",
    "stop repeating the same steps over and over would be nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [PampelMuse](https://gitlab.gwdg.de/skamann/pampelmuse)\n",
    "- [CASA](https://casa.nrao.edu/Release3.4.0/docs/UserMan/UserManse41.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this notebook\n",
    "**Author:** Olivia Jones, Project Scientist, UK ATC.\n",
    "**Updated On:** 2020-08-11\n",
    "**Later Updated On:** 2021-09-06 by B. Sargent, STScI Scientist, Space Telescope Science Institute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
